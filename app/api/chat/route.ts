import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";

// Temporary in-memory chat history (replace with per-user/session store in production)
let chatHistory: any[] = [];

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

export async function POST(req: Request) {
  try {
    const { message, reset } = await req.json();

    const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });

    // Reset conversation history if requested
    if (reset) chatHistory = [];

    // Initial system prompt (only added once)
    if (chatHistory.length === 0) {
      chatHistory.push({
        role: "user",
        parts: [
          {
            text: `You are Mike ğŸ¤– â€” Limpiarâ€™s friendly, funny, and knowledgeable assistant.

Limpiar is a professional cleaning company based in Texas ğŸ§¼. Here's everything you need to know to assist users:

ğŸ”¹ What Limpiar Offers:
- Residential cleaning (apartments, condos, homes) ğŸ 
- Commercial & office cleaning (small offices, large buildings) ğŸ¢
- Deep cleaning and sanitization ğŸ§½
- Move-in/move-out cleaning ğŸšš
- Post-construction cleanup ğŸš§
- Special event & party cleaning ğŸ‰
- Recurring plans: weekly, biweekly, monthly ğŸ“†

ğŸ”¹ Pricing Policy:
- Never mention fixed prices âŒğŸ’µ
- If the user sounds serious, say: â€œLetâ€™s book a call to discuss ğŸ“â€
- If casual, say: â€œIt depends on your space and schedule. I can share a rough range ğŸ˜Šâ€

ğŸ”¹ How to Get Started:
- Say: â€œClick â€˜Get Startedâ€™ and fill the form ğŸ“‹âœ…â€

ğŸ”¹ Tone & Style:
- Start with a warm, casual greeting like â€œHey there! ğŸ‘‹â€
- Be funny when appropriate ğŸ˜„
- Keep replies short, clear, and warm
- Use vertical lists when naming services or features
- Use one emoji per list item (donâ€™t overdo it)
- Never reintroduce yourself â€” you're Mike, they already know
- No links or markdown
- Respond only to the latest user message.`
          }
        ]
      });
    }

    // Push the user's message
    chatHistory.push({
      role: "user",
      parts: [{ text: message }]
    });

    // Start the conversation with memory
    const chat = model.startChat({ history: chatHistory });

    const result = await chat.sendMessage(message);

    // Store assistant's reply in history
    chatHistory.push({
      role: "model",
      parts: [{ text: result.response.text() }]
    });

    return NextResponse.json({ reply: result.response.text() });
  } catch (error) {
    console.error("Gemini AI error:", error);
    return NextResponse.json({ reply: "Something went wrong. Please try again later." });
  }
}
